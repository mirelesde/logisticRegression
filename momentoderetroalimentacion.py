# -*- coding: utf-8 -*-
"""MomentoDeRetroalimentacion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Is1FVA-wqOw8oX_igP8snlRlIQefhlpb

# Cargando datos

Cargamos los datos que utilizaremos. Utillizaremos el clásico wine dataset, un dataset para clasificación que tiene tres clases. Los tres vinos son italianos, las clases representan de qué cultivo son (no tienen nombre, solo 1, 2 o 3). En este caso solo queremos predecir si cada caso corrsponde con la clase 2 o no.
"""

from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
wine = load_wine()
X = wine["data"]
y = (wine["target"] == 2).astype(int) # Si el vino es

"""# Escalamiento

Escalamos los features para acelerar la convergencia y mejorar el performance del modelo
"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)

"""# Dividiendo los datos en test y train

Usamos la función *test_train_split* para dividir nuestros datos en un conjunto de entrenamiento y otro de prueba.
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""# Creando Theta

Para theta, tenemos un theta para cada feature. También añadimos uno final que es un bias.
"""

import numpy as np
theta = np.random.randn(len(X_train[0]) + 1, 1)
theta

"""Añadimos un uno al vector de features para que el bias que añadimos anteriormente si sea considerado al multiplicar."""

X_vect = np.c_[np.ones((len(X_train), 1)), X_train]
print(X_vect[:5])
print(X_vect.shape)

import math
def sigmoid_function(X):
  return 1/(1+math.e**(-X)) # esta es la forma general de un modelo logístico

import matplotlib.pyplot as plt

def log_regression(X, y, theta, alpha, epochs):
  y_ = np.reshape(y, (len(y), 1)) # para que shape sea (len(y),1)
  N = len(X)
  avg_loss_list = []
  for epoch in range(epochs):
    sigmoid_x_theta = sigmoid_function(X_vect.dot(theta))
    grad = (1/N) * X_vect.T.dot(sigmoid_x_theta - y_)
    theta = theta - (alpha * grad)
    hyp = sigmoid_function(X_vect.dot(theta))
    avg_loss = -np.sum(np.dot(y_.T, np.log(hyp) + np.dot((1-y_).T, np.log(1-hyp)))) / len(hyp)
    if epoch % 10000 == 0:
      print('epoch: {} | avg_loss: {}'.format(epoch, avg_loss))

    avg_loss_list.append(avg_loss)
  plt.plot(np.arange(1, epochs), avg_loss_list[1:], color='red')
  plt.title('Cost function')
  plt.xlabel('Epochs')
  plt.ylabel('Cost')
  plt.show()

epochs = 1000000
log_regression(X_train, y_train, theta, alpha, epochs)

"""# Probando el modelo con los datos de preuba"""

X_test = np.c_[np.ones((len(X_test), 1)), X_test]
print(X_test)

"""A continuación realizamos las predicciones según lo que obtuvimos en el entrenamiento."""

y_pred = sigmoid_function(X_test.dot(theta))

"""A continuación evaluamos la eficacia de nuestro modelo comparando nuestras predicciones contra los valores de y_test"""

def classify(x): # Convertir el valor continuo en uno binario, 0 o 1
  if x > 0.5:
    return 1
  return 0

def evaluate(y_test, y_pred):
  correct = 0
  for i in range(len(y_test)):
    print('Actual value:\t\t', y_test[i])
    print('Predicted value:\t', classify(y_pred[i]))
    print('Full predicted value: \t', y_pred[i])
    print('Correct?:\t\t', (y_test[i] == classify(y_pred[i])))
    print()

    if y_test[i] == classify(y_pred[i]): correct += 1

  print('---')
  print('Correct: ', correct, '/', len(y_test))
  print('Accuracy:', (correct/len(y_test))*100, '%')

evaluate(y_test, y_pred)

"""Al analizar los resultados, el modelo no fue nada bueno prediciendo. Al ejecutar el código muchas veces, el mejor accuracy que obtuve fue de 75%, sin embargo, el resto del tiempo obtengo valores por debajo del 50%. El entrenamiento del modelo está realizado de forma correcta. Quizás las fallas para predecir los resultados se deben al bajo nivel de entrenamiento del modelo, ya que solo cuenta con 142 registros en total. Al dividir estos datos en conjuntos de entrenamiento y prueba, solo quedan 108 registros para entrenar al modelo. Independientemente de la cantidad de epochs por las que entrenemos al modelo, si la cantidad de datos de entrenamiento no es suficientemente grande el modelo no logrará ser preciso."""

